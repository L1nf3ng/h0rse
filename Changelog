~ 2019.05.14 ~

写到这里，基本上爬虫部分能跑通了。但遗留下不少问题：

1. 之前出过一个奇葩异常，后来查明是重定向导致的，如：http://abc/def.php?url=http://dilidili.jpg
   这种重定向类在做解析是误将？后面的都当做了参数，从而绕过了后缀名检测。requests模块默认跟踪重定向，这
   里直接关闭掉allow_redirects=False，这样状态码就可返回301/302；

2. 比较了爬取已爬取url和队列中待爬取url的数量级变化，发现如果不限定Scope，会产生大量待爬内容。因此决定下
   个版本将二级域名、对应ip地址等范围作为限制，减少爬取数量；

3. 有用信息的搜集，在调试过程中已经发现一些不太注意的可下载文档、返回内容异常的请求都对后期渗透很有用，可以
   进一步加入一些检测内容来提取它们；

4. 对其他请求方法支撑较弱，且自动填表单的功能写的实在糟糕，后期考虑换个思路重写；

不足：

1. Set-Cookie的处理与维护，登录界面暴露给用户
